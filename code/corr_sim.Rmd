---
title: "Correlation estimation"
author: "Guillaume A. Rousselet"
date: "`r Sys.Date()`"
output:
  pdf_document:
    dev: cairo_pdf
    number_sections: no
    toc: yes
    toc_depth: 2
    #latex_engine: xelatex
---

# Dependencies
```{r message=FALSE, warning=FALSE}
# code to compute kernel density estimates - see:
# Wilcox, R.R. (2017) Introduction to Robust Estimation and Hypothesis Testing. Academic Press, 4th edition., San Diego, CA.
source('./functions/akerd.txt')
library(ggplot2)
library(tibble)
# library(cowplot)
library(beepr)
```

```{r}
sessionInfo()
```

# Define mode function
```{r}
# https://www.r-bloggers.com/computing-the-mode-in-r/
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```

# Check `cor()` function

We generate 10,000 correlations from uncorrelated samples of size n = 10.
The distribution should be 

## n = 10
```{r}
set.seed(21)
n <- 10 # sample size
rho <- 0 # effect size
p <- 20000 # number of simulations
allcorr <- replicate(p, cor(MASS::mvrnorm(n = n, mu = c(0,0), Sigma = matrix(c(1, rho, rho, 1), nrow = 2, byrow = TRUE)))[1,2])
# plot histogram
hist(allcorr, xlim = c(-1, 1))
```

## n = 100
```{r}
set.seed(21)
n <- 100 # sample size
rho <- 0 # effect size
p <- 20000 # number of simulations
allcorr <- replicate(p, cor(MASS::mvrnorm(n = n, mu = c(0,0), Sigma = matrix(c(1, rho, rho, 1), nrow = 2, byrow = TRUE)))[1,2])
# plot histogram
hist(allcorr, xlim = c(-1, 1))
```

# Fake correlation

Generate 20 variables, pick largest bivariate correlation, plot it.
```{r}
n_var <- 20
mu <- rep(0, n_var)
sigma <- diag(x = 1, n_var, n_var)
set.seed(123)
variables <- MASS::mvrnorm(n = 30, mu = mu, Sigma = sigma)
cor_matrix <- cor(variables)
cor_matrix[!upper.tri(cor_matrix)] <- NA
which(abs(cor_matrix) == max(abs(cor_matrix), na.rm = TRUE), arr.ind = TRUE)

plot(variables[, 3], variables[, 4])
cor(variables[, 3], variables[, 4])
cor.test(variables[, 3], variables[, 4])

out <- cor.test(variables[, 3], variables[, 4])

df <- tibble(x=variables[, 3], y=variables[, 4])

ggplot(data=df, aes(x=x, y=y)) + theme_classic() +
  geom_point(shape=21, size=3, fill="yellow", alpha=0.8) +
  geom_smooth(method=lm) +
  coord_cartesian(xlim=c(-2.5, 2.5), ylim=c(-2.5, 2.5)) +
  theme(plot.title = element_text(size=20),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 14, colour="black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = "right",
        legend.text=element_text(size = 16),
        legend.title=element_text(size = 18),
        panel.background = element_rect(fill="grey95")) +
  labs(x = "Variable 1", y = "Variable 2") +
  # guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
  #   title = "Precision \n(within +/-)")) + # change legend title
  ggtitle(paste0("r=",round(out$estimate,digits = 2),
                 ", t=",round(out$statistic,digits = 2),
                 ", p=",round(out$p.value,digits = 4))) 
```

Save figure
```{r, eval = FALSE}
ggsave(filename='./figures/figure_rand_corr.pdf',width=7,height=5) 
```

# Correlation estimates as a function of sample size

## Parameters
```{r}
nseq <- c(seq(10, 100, 10), 150, 200, 300) # sample sizes
Nn <- length(nseq)
pts <- seq(-1, 1, 0.025) # KDE points
Np <- length(pts)
preseq <- seq(0.025, 0.2, 0.025) # precision bounds
Npre <- length(preseq)
rho <- 0
p <- 200 # 19900 correlations - sum(upper.tri(matrix(0, p, p), diag = FALSE))
Nsim <- 20000
```

## Generate data
```{r eval=FALSE}
set.seed(21)
# declare result matrices
res.cor <- matrix(data = 0, nrow = Np, ncol = Nn) 
res.pre <- matrix(data = 0, nrow = Npre, ncol = Nn)

for(iter.n in 1:Nn){
  beep(2)
  print(paste0("Sample size = ", nseq[iter.n]))
  
  allcorr <- replicate(Nsim, cor(MASS::mvrnorm(n = nseq[iter.n], mu = c(0,0), Sigma = matrix(c(1, rho, rho, 1), nrow = 2, byrow = TRUE)))[1,2])
  
res.cor[,iter.n] <- akerd(allcorr, pyhat=TRUE, pts=pts, plotit=FALSE)
  
  # Probability of getting estimate within +/- x of population value
  for(iter.p in 1:Npre){
    res.pre[iter.p, iter.n] <- mean(allcorr <= (rho + preseq[iter.p]) & allcorr >= (rho - preseq[iter.p]))
  }
  
}

save(res.cor, res.pre,
     file = "./data/samp_dist.RData")
beep(8)
```

Wolfgang Viechtbauer mentioned on [Twitter](https://twitter.com/wviechtb/status/1002875957374521346) “that one can just compute the density of r directly (no need to simulate). For example: [link](https://gist.github.com/wviechtb/e87ee35ea5544a3a5f875f61e270cd18). Then everything is nice and smooth”. Here we use simulations because the code could be modified to include data that are not bivariate normal, for instance with heteroscedasticity. See example code using conditional variances [here](https://www.r-bloggers.com/simulating-from-the-bivariate-normal-distribution-in-r) and in the `corr_power.Rmd` file.

## Plot kernel density estimates
```{r}
# get data
load("./data/samp_dist.RData")

# plot only a subsample of sizes:
toget <- c(1,2,3,4,5,7,10,11,13) # seq(1:Nn)

# make data frame
fm <- array(0, dim = c(Np, length(toget)+1)) # make full matrix
fm[,1] <- pts
fm[,2:(length(toget)+1)] <- res.cor[, toget]
colnames(fm) <- c("x",nseq[toget])
df <- as_tibble(fm)
df <- tidyr::gather(df, SS, Density,2:(length(toget)+1))
df[[2]] <- as.character(df[[2]])
df[[2]] <- factor(df[[2]], levels=unique(df[[2]]))

# make plot
p <- ggplot(df, aes(x, Density)) + theme_classic() +
          geom_line(aes(colour = SS), size = 1)  + 
          scale_color_viridis_d(option = "B", end = 0.9) + 
          theme(axis.title.x = element_text(size = 18),
                axis.text = element_text(size = 14, colour = "black"),
                axis.title.y = element_text(size = 18),
                legend.key.width = unit(1.5,"cm"),
                legend.text = element_text(size = 16),
                legend.title = element_text(size = 18),
                legend.position = c(.85, .55),
                plot.title = element_text(size = 20, colour = "black"),
                panel.background = element_rect(fill="grey90")) +
          scale_x_continuous(limits = c(-1, 1), 
                             breaks = seq(-1, 1, 0.2)) +
  labs(x = "Correlation estimates", y = "Density") +
  # ggtitle("Correlation sampling distributions") +
  # ggtitle("\u03c1=0") +
  ggtitle("rho=0") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
        title="Sample size")) # change legend title
p.sd <- p
p
```

#### Mean and median correlations
```{r}
load("./data/rpval_04.RData")
round(apply(res.r, 2, mean), digits = 3)
round(apply(res.r, 2, median), digits = 3)
round(apply(res.r, 2, Mode), digits = 3)
```

## Correlations conditional on p values

Reporting correlation results conditional on statistical significance ($p\leq0.05$) leads to inflated effect size estimation in the literature. This estimation bias increases with lower sample sizes.

### Parameters
```{r}
nseq <- c(seq(10, 100, 10), 150, 200, 300) # sample sizes
Nn <- length(nseq)
pts <- seq(-1, 1, 0.025) # KDE points
Np <- length(pts)
p <- 2
mu <- 0
nsim <- 50000
rho <- 0
sigma <- diag(p)
sigma[sigma==0] <- rho
```

### Simulation
```{r eval=FALSE}

set.seed(21)

res.r <- matrix(data = 0, nrow = nsim, ncol = Nn) # R values
res.p <- matrix(data = 0, nrow = nsim, ncol = Nn) # p values

for(iter.n in 1:Nn){
  beep(2)
  print(paste0("Sample size = ", nseq[iter.n]))
  
  for(iter in 1:nsim){
    
    data <- MASS::mvrnorm(n = nseq[iter.n], mu = rep(mu, p), Sigma = sigma)
    out <- cor.test(data[,1],data[,2], method = "pearson")
    res.r[iter,iter.n] <- out$estimate
    res.p[iter,iter.n] <- out$p.value

  }
}

# hist(res.r)
# mean(res.p<=0.05)

save(res.r, res.p,
     file = "./data/rpval.RData")
beep(8)
```

### Make KDE
```{r eval=FALSE}
# get data
load("./data/rpval.RData")

kde.r.ori <- matrix(data = 0, nrow = Np, ncol = Nn) 
kde.r.cond <- matrix(data = 0, nrow = Np, ncol = Nn) 

for(iter.n in 1:Nn){
  beep(2)
  print(paste0("Sample size = ", nseq[iter.n]))
  
  kde.r.ori[,iter.n] <- akerd(res.r[,iter.n], pyhat=TRUE, pts=pts, plotit=FALSE)
  kde.r.cond[,iter.n] <- akerd(res.r[res.p[,iter.n]<=0.05,iter.n], pyhat=TRUE, pts=pts, plotit=FALSE)
  
}

save(kde.r.ori, kde.r.cond,
     file = "./data/rpval.kde.RData")
beep(8)
```

### Plot KDE of conditional correlation estimates 
```{r}
# get data
load("./data/rpval.kde.RData")

# make data frame
fm <- array(0, dim = c(Np, length(toget)+1)) # make full matrix
fm[,1] <- pts
fm[,2:(length(toget)+1)] <- kde.r.cond[,toget]
colnames(fm) <- c("x",nseq[toget])
df <- as_tibble(fm)
df <- tidyr::gather(df, SS, Density,2:(length(toget)+1))
df[[2]] <- as.character(df[[2]])
df[[2]] <- factor(df[[2]], levels=unique(df[[2]]))

# make plot
p <- ggplot(df, aes(x, Density)) + theme_classic() +
          geom_line(aes(colour = SS), size = 1)  + 
          scale_color_viridis_d(option = "B", end = 0.9) + 
          theme(axis.title.x = element_text(size = 18),
                axis.text = element_text(size = 14, colour = "black"),
                axis.title.y = element_text(size = 18),
                legend.key.width = unit(1.5,"cm"),
                legend.text = element_text(size = 16),
                legend.title = element_text(size = 18),
                legend.position = "none",
                plot.title = element_text(size = 20, colour = "black"),
                panel.background = element_rect(fill="grey90")) +
          scale_x_continuous(limits = c(-1, 1), 
                             breaks = seq(-1, 1, 0.2)) +
  labs(x = "Correlation estimates", y = "Density") +
  # ggtitle("\u03c1=0: p\u22640.05") +
  ggtitle("rho=0: p<=0.05") +
  # ggtitle("Correlation sampling distributions") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
        title="Sample size")) # change legend title
p
p.csd <- p
```

## Estimation precision (rho=0)
```{r}
df <- tibble(`Proportion` = as.vector(res.pre),
             `Precision` = rep(preseq, Nn),
             `Size` = rep(nseq, each = Npre))

df$Precision <- as.character(df$Precision)
df$Precision <- factor(df$Precision, levels=unique(df$Precision))

# data frame to plot segments
tmp.pos <- approx(y=nseq,x=res.pre[4,],xout=0.70)$y
df.seg1 <- tibble(x=0, xend=tmp.pos,
                  y=0.7, yend=0.7)
df.seg2 <- tibble(x=tmp.pos, xend=tmp.pos,
                  y=0.7, yend=0)
tmp.pos <- approx(y=nseq,x=res.pre[8,],xout=0.90)$y
df.seg3 <- tibble(x=0, xend=tmp.pos,
                  y=0.9, yend=0.9)
df.seg4 <- tibble(x=tmp.pos, xend=tmp.pos,
                  y=0.9, yend=0)

# make plot
p <- ggplot(df, aes(x=Size, y=Proportion)) + theme_classic() +
  # geom_abline(intercept=0.7, slope=0, colour="grey20") +
  geom_segment(data = df.seg1, aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_segment(data = df.seg2, aes(x=x, y=y, xend=xend, yend=yend), 
               arrow = arrow(length = unit(0.2, "cm"))) +
  geom_segment(data = df.seg3, aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_segment(data = df.seg4, aes(x=x, y=y, xend=xend, yend=yend), 
               arrow = arrow(length = unit(0.2, "cm"))) +
  geom_line(aes(colour = Precision), size = 1) + 
  scale_color_viridis_d(end = 0.9) +
  scale_x_continuous(breaks=nseq, 
            labels = c("10",  "",  "30", "", "50",  "", "70", "", "90", "", "150", "200", "300")) + 
  scale_y_continuous(breaks=seq(0, 1, 0.1)) +
  coord_cartesian(ylim=c(0, 1)) +
  theme(plot.title = element_text(size=20),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 14, colour="black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = "right",
        legend.text=element_text(size = 16),
        legend.title=element_text(size = 18),
        panel.background = element_rect(fill="grey90")) +
  labs(x = "Sample size", y = "Proportion of estimates") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
    title = "Precision \n(within +/-)")) + # change legend title
  ggtitle("Estimation precision (\u03c1=0)")
  # ggtitle("Estimation precision (rho=0)") 
p
p.precision <- p
```

For 70% of estimates to be within +/- 0.1 of the true correlation value (between -0.1 and 0.1), we need at least `r round(approx(y=nseq,x=res.pre[4,],xout=0.70)$y)` observations.

For 90% of estimates to be within +/- 0.2 of the true correlation value (between -0.2 and 0.2), we need at least `r round(approx(y=nseq,x=res.pre[8,],xout=0.90)$y)` observations.

# Probability to replicate an effect
For a given precision, what is the probability to observe similar effects in two consecutive experiments? In other words, what is the probability that two measurements differ by at most a certain amount?

## Parameters
```{r}
nseq <- c(seq(10, 100, 10), 150, 200, 300) # sample sizes
Nn <- length(nseq)
preseq <- seq(0.025, 0.2, 0.025) # precision bounds
Npre <- length(preseq)
g <- 0
h <- 0
rho <- 0
p <- 500 # 124750 correlations - sum(upper.tri(matrix(0, p, p), diag = FALSE))
Nsim <- 20000
```

## Generate data
```{r eval=FALSE}
set.seed(21)
# declare result matrices
res.rep <- matrix(data = 0, nrow = Npre, ncol = Nn)

for(iter.n in 1:Nn){
  beep(2)
  print(paste0("Sample size = ", nseq[iter.n]))
 
   allcorr1 <- replicate(Nsim, cor(MASS::mvrnorm(n = nseq[iter.n], mu = c(0,0), Sigma = matrix(c(1, rho, rho, 1), nrow = 2, byrow = TRUE)))[1,2])
  
  allcorr2 <- replicate(Nsim, cor(MASS::mvrnorm(n = nseq[iter.n], mu = c(0,0), Sigma = matrix(c(1, rho, rho, 1), nrow = 2, byrow = TRUE)))[1,2])
  
  # Probability of getting estimates at most x units of each other
  for(iter.p in 1:Npre){
    res.rep[iter.p, iter.n] <- mean( abs(allcorr1-allcorr2) <= (preseq[iter.p]*2) )
  }
  
}

save(res.rep,
     file = "./data/replication.RData")
beep(8)
```

## Illustrate results
```{r}
load("./data/replication.RData")
df <- tibble(`Proportion` = as.vector(res.rep),
             `Precision` = rep(preseq*2, Nn),
             `Size` = rep(nseq, each = Npre))

df$Precision <- as.character(df$Precision)
df$Precision <- factor(df$Precision, levels=unique(df$Precision))

# data frame to plot segments
tmp.pos <- approx(y=nseq,x=res.rep[4,],xout=0.8)$y
df.seg1 <- tibble(x=0, xend=tmp.pos,
                  y=0.8, yend=0.8)
df.seg2 <- tibble(x=tmp.pos, xend=tmp.pos,
                  y=0.8, yend=0)

# make plot
p <- ggplot(df, aes(x=Size, y=Proportion)) + theme_classic() +
  geom_segment(data = df.seg1, aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_segment(data = df.seg2, aes(x=x, y=y, xend=xend, yend=yend),
               arrow = arrow(length = unit(0.2, "cm"))) +
  geom_line(aes(colour = Precision), size = 1) + 
  scale_color_viridis_d(end = 0.9) +
  scale_x_continuous(breaks=nseq, 
            labels = c("10",  "",  "30", "", "50",  "", "70", "", "90", "", "150", "200", "300")) + 
  scale_y_continuous(breaks=seq(0, 1, 0.1)) +
  coord_cartesian(ylim=c(0, 1)) +
  theme(plot.title = element_text(size=20),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 14, colour="black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = "right",
        legend.text=element_text(size = 16),
        legend.title=element_text(size = 18),
        panel.background = element_rect(fill="grey90")) +
  labs(x = "Sample size", y = "Proportion of replications") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
    title = "Difference \n(at most)")) + # change legend title
  ggtitle("Replication precision") 
p
p.replication <- p
# save figure
# ggsave(filename='./figures/figure_replication.pdf',width=9,height=5) 
```

For 80% of replications to be at most 0.2 apart, we need at least `r round(approx(y=nseq,x=res.rep[4,],xout=0.8)$y)` observations.

What happens when there is an effect?

# Correlation estimates as a function of rho for fixed n
For a given sample size, estimate correlations for different Pearson's population (rho) correlations.

## Parameters
```{r}
n <- 30 # sample size
rhoseq <- seq(0, 0.9, 0.1) # rho
Nrho <- length(rhoseq)
pts <- seq(-1, 1, 0.025) # KDE points
Np <- length(pts)
preseq <- seq(0.025, 0.2, 0.025) # precision bounds
Npre <- length(preseq)
# rho <- 0
p <- 200 # 19900 correlations - sum(upper.tri(matrix(0, p, p), diag = FALSE))
Nsim <- 20000
```

## Generate data
```{r eval=FALSE}
set.seed(666)
# declare result matrices
res.cor <- matrix(data = 0, nrow = Np, ncol = Nrho)
res.pre <- matrix(data = 0, nrow = Npre, ncol = Nrho)

for(iter.rho in 1:Nrho){
  beep(2)
  print(paste0("rho = ", rhoseq[iter.rho]))
  
  allcorr <- replicate(Nsim, cor(MASS::mvrnorm(n = n, mu = c(0,0), Sigma = matrix(c(1, rhoseq[iter.rho], rhoseq[iter.rho], 1), nrow = 2, byrow = TRUE)))[1,2])
  
  res.cor[,iter.rho] <- akerd(allcorr, pyhat=TRUE, pts=pts, plotit=FALSE)
  
  # Probability of getting estimate within +/- x of population value
  for(iter.p in 1:Npre){
    res.pre[iter.p, iter.rho] <- mean( (allcorr-rhoseq[iter.rho]) <= (preseq[iter.p]) & (allcorr-rhoseq[iter.rho]) >= (-1*preseq[iter.p]))
  }
  
}

save(res.cor, res.pre,
     file = "./data/samp_dist_rho.RData")
beep(8)
```

## Plot kernel density estimates
```{r}
# get data
load("./data/samp_dist_rho.RData")

# make data frame
fm <- array(0, dim = c(Np, Nrho+1)) # make full matrix
fm[,1] <- pts
fm[,2:(Nrho+1)] <- res.cor
colnames(fm) <- c("x",rhoseq)
df <- as_tibble(fm)
df <- tidyr::gather(df, RHO, Density,2:(Nrho+1))
df[[2]] <- as.character(df[[2]])
df[[2]] <- factor(df[[2]], levels=unique(df[[2]]))

# make plot
p <- ggplot(df, aes(x, Density)) + theme_classic() +
          geom_line(aes(colour = RHO), size = 1)  + 
          scale_color_viridis_d(option = "C", end = 0.9) + 
          theme(axis.title.x = element_text(size = 18),
                axis.text = element_text(size = 14, colour = "black"),
                axis.title.y = element_text(size = 18),
                legend.key.width = unit(1.5,"cm"),
                legend.text = element_text(size = 16),
                legend.title = element_text(size = 18),
                legend.position = "right",
                plot.title = element_text(size = 20, colour = "black"),
                panel.background = element_rect(fill="grey90")) +
          scale_x_continuous(limits = c(-1, 1), 
                             breaks = seq(-1, 1, 0.2)) +
  labs(x = "Correlation estimates", y = "Density") +
  ggtitle("Correlation sampling distributions (n=30)") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
        title="Population \ncorrelation")) # change legend title
p

# save figure
ggsave(filename='./figures/figure_samp_dist_rho.pdf',width=9,height=5) 
```

## Precision
```{r}
df <- tibble(`Proportion` = as.vector(res.pre),
             `Precision` = rep(preseq, Nrho),
             `Rho` = rep(rhoseq, each = Npre))

df$Precision <- as.character(df$Precision)
df$Precision <- factor(df$Precision, levels=unique(df$Precision))

# make plot
p <- ggplot(df, aes(x=Rho, y=Proportion)) + theme_classic() +
  geom_line(aes(colour = Precision), size = 1) + 
  scale_color_viridis_d(end = 0.9) +
  scale_x_continuous(breaks=rhoseq) + 
  scale_y_continuous(breaks=seq(0, 1, 0.1)) +
  coord_cartesian(ylim=c(0, 1)) +
  theme(plot.title = element_text(size=20),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 14, colour="black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = "right",
        legend.text=element_text(size = 16),
        legend.title=element_text(size = 18),
        panel.background = element_rect(fill="grey90")) +
  labs(x = "Population correlation", y = "Proportion of estimates") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
    title = "Precision \n(within +/-)")) + # change legend title
  ggtitle("Measurement precision (n=30)") 
p

# save figure
# ggsave(filename='./figures/figure_precision_rho.pdf',width=9,height=5) 
```

Let's look in more detail at the sampling distributions for a generous rho = 0.4.

# Correlation estimates as a function of sample size (rho=0.4)

## Parameters
```{r}
nseq <- c(seq(10, 100, 10), 150, 200, 300) # sample sizes
Nn <- length(nseq)
pts <- seq(-1, 1, 0.025) # KDE points
Np <- length(pts)
preseq <- seq(0.025, 0.2, 0.025) # precision bounds
Npre <- length(preseq)
rho <- 0.4
p <- 200 # 19900 correlations - sum(upper.tri(matrix(0, p, p), diag = FALSE))
Nsim <- 20000
```

## Generate data
```{r eval=FALSE}
set.seed(21)
# declare result matrices
res.cor <- matrix(data = 0, nrow = Np, ncol = Nn) 
res.pre <- matrix(data = 0, nrow = Npre, ncol = Nn)

for(iter.n in 1:Nn){
  beep(2)
  print(paste0("Sample size = ", nseq[iter.n]))
 
  allcorr <- replicate(Nsim, cor(MASS::mvrnorm(n = nseq[iter.n], mu = c(0,0), Sigma = matrix(c(1, rho, rho, 1), nrow = 2, byrow = TRUE)))[1,2])
  
  res.cor[,iter.n] <- akerd(allcorr, pyhat=TRUE, pts=pts, plotit=FALSE)
  
  # Probability of getting estimate within +/-x% of population value
  for(iter.p in 1:Npre){
    res.pre[iter.p, iter.n] <- mean((allcorr-rho) <= preseq[iter.p] & (allcorr-rho) >= (-1*preseq[iter.p]))
  }
  
}

save(res.cor, res.pre,
     file = "./data/samp_dist_rho04.RData")
beep(8)
```

## Plot kernel density estimates
```{r}
# get data
load("./data/samp_dist_rho04.RData")

# make data frame
fm <- array(0, dim = c(Np, length(toget)+1)) # make full matrix
fm[,1] <- pts
fm[,2:(length(toget)+1)] <- res.cor[,toget]
colnames(fm) <- c("x",nseq[toget])
df <- as_tibble(fm)
df <- tidyr::gather(df, SS, Density,2:(length(toget)+1))
df[[2]] <- as.character(df[[2]])
df[[2]] <- factor(df[[2]], levels=unique(df[[2]]))

# make plot
p <- ggplot(df, aes(x, Density)) + theme_classic() +
          geom_line(aes(colour = SS), size = 1)  + 
          scale_color_viridis_d(option = "B", end = 0.9) + 
          theme(axis.title.x = element_text(size = 18),
                axis.text = element_text(size = 14, colour = "black"),
                axis.title.y = element_text(size = 18),
                legend.key.width = unit(1.5,"cm"),
                legend.text = element_text(size = 16),
                legend.title = element_text(size = 18),
                legend.position = "none",
                plot.title = element_text(size = 20, colour = "black"),
                panel.background = element_rect(fill="grey90")) +
          scale_x_continuous(limits = c(-1, 1), 
                             breaks = seq(-1, 1, 0.2)) +
  labs(x = "Correlation estimates", y = "Density") +
  # ggtitle("Correlation sampling distributions (rho=0.4)") +
  # ggtitle("\u03c1=0.4") +
  ggtitle("rho=0.4") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
        title="Sample size")) # change legend title
p
p.sd04 <- p

# save figure
# ggsave(filename='./figures/figure_sampling_distributions_rho04.pdf',width=9,height=5) 
```

## Correlations conditional on p values

### Parameters
```{r}
nseq <- c(seq(10, 100, 10), 150, 200, 300) # sample sizes
Nn <- length(nseq)
pts <- seq(-1, 1, 0.025) # KDE points
Np <- length(pts)
p <- 2
mu <- 0
nsim <- 50000
rho <- 0.4
sigma <- diag(p)
sigma[sigma==0] <- rho
```

### Simulation
```{r eval=FALSE}

set.seed(21)

res.r <- matrix(data = 0, nrow = nsim, ncol = Nn) # R values
res.p <- matrix(data = 0, nrow = nsim, ncol = Nn) # p values

for(iter.n in 1:Nn){
  beep(2)
  print(paste0("Sample size = ", nseq[iter.n]))
  
  for(iter in 1:nsim){
    
    data <- MASS::mvrnorm(n = nseq[iter.n], mu = rep(mu, p), Sigma = sigma)
    out <- cor.test(data[,1],data[,2], method = "pearson")
    res.r[iter,iter.n] <- out$estimate
    res.p[iter,iter.n] <- out$p.value

  }
}

hist(res.r)
mean(res.p<=0.05)

save(res.r, res.p,
     file = "./data/rpval_04.RData")
beep(8)
```

Proportion of simulations with negative sign and p<0.05 for n = 10:
```{r}
load("./data/rpval_04.RData")
mean(res.r[res.p[,1]<0.05,1]<0)
```

### Make KDE
```{r eval=FALSE}
# get data
load("./data/rpval_04.RData")

kde.r.ori <- matrix(data = 0, nrow = Np, ncol = Nn) 
kde.r.cond <- matrix(data = 0, nrow = Np, ncol = Nn) 

for(iter.n in 1:Nn){
  
  print(paste0("Sample size = ", nseq[iter.n]))
  
  kde.r.ori[,iter.n] <- akerd(res.r[,iter.n], pyhat=TRUE, pts=pts, plotit=FALSE)
  kde.r.cond[,iter.n] <- akerd(res.r[res.p[,iter.n]<=0.05,iter.n], pyhat=TRUE, pts=pts, plotit=FALSE)
  
}

save(kde.r.ori, kde.r.cond,
     file = "./data/rpval.kde_04.RData")
```

### Plot conditional correlation estimates
```{r}
# get data
load("./data/rpval.kde_04.RData")

# make data frame
fm <- array(0, dim = c(Np, length(toget)+1)) # make full matrix
fm[,1] <- pts
fm[,2:(length(toget)+1)] <- kde.r.cond[,toget]
colnames(fm) <- c("x",nseq[toget])
df <- as_tibble(fm)
df <- tidyr::gather(df, SS, Density,2:(length(toget)+1))
df[[2]] <- as.character(df[[2]])
df[[2]] <- factor(df[[2]], levels=unique(df[[2]]))

# make plot
p <- ggplot(df, aes(x, Density)) + theme_classic() +
          geom_line(aes(colour = SS), size = 1)  + 
          scale_color_viridis_d(option = "B", end = 0.9) + 
          theme(axis.title.x = element_text(size = 18),
                axis.text = element_text(size = 14, colour = "black"),
                axis.title.y = element_text(size = 18),
                legend.key.width = unit(1.5,"cm"),
                legend.text = element_text(size = 16),
                legend.title = element_text(size = 18),
                legend.position = "none",
                plot.title = element_text(size = 20, colour = "black"),
                panel.background = element_rect(fill="grey90")) +
          scale_x_continuous(limits = c(-1, 1), 
                             breaks = seq(-1, 1, 0.2)) +
  labs(x = "Correlation estimates", y = "Density") +
  # ggtitle("Correlation sampling distributions") +
  # ggtitle("\u03c1=0.4: p\u22640.05") +
  ggtitle("rho=0.4: p<=0.05") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
        title="Sample size")) # change legend title
p
p.csd04 <- p

# save figure
# ggsave(filename='./figures/figure_rpval_cond_04.pdf',width=9,height=5) 
```

#### Mean and median correlations
```{r}
load("./data/rpval_04.RData")

mean.res <- vector(mode = "numeric", length = Nn) 
median.res <- vector(mode = "numeric", length = Nn) 
mode.res <- vector(mode = "numeric", length = Nn) 

for(iter.n in 1:Nn){

mean.res[iter.n] <- round(mean(res.r[res.p[,iter.n]<=0.05,iter.n]), digits=3)
median.res[iter.n] <- round(median(res.r[res.p[,iter.n]<=0.05,iter.n]), digits=3)
mode.res[iter.n] <- round(Mode(res.r[res.p[,iter.n]<=0.05,iter.n]), digits=3)
}

mean.res
median.res
mode.res
```

## Precision
```{r}
df <- tibble(`Proportion` = as.vector(res.pre),
             `Precision` = rep(preseq, Nn),
             `Size` = rep(nseq, each = Npre))

df$Precision <- as.character(df$Precision)
df$Precision <- factor(df$Precision, levels=unique(df$Precision))

# data frame to plot segments
tmp.pos <- approx(y=nseq,x=res.pre[4,],xout=0.70)$y
df.seg1 <- tibble(x=0, xend=tmp.pos,
                  y=0.7, yend=0.7)
df.seg2 <- tibble(x=tmp.pos, xend=tmp.pos,
                  y=0.7, yend=0)
tmp.pos <- approx(y=nseq,x=res.pre[8,],xout=0.90)$y
df.seg3 <- tibble(x=0, xend=tmp.pos,
                  y=0.9, yend=0.9)
df.seg4 <- tibble(x=tmp.pos, xend=tmp.pos,
                  y=0.9, yend=0)

# make plot
p <- ggplot(df, aes(x=Size, y=Proportion)) + theme_classic() +
  # geom_abline(intercept=0.7, slope=0, colour="grey20") +
  geom_segment(data = df.seg1, aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_segment(data = df.seg2, aes(x=x, y=y, xend=xend, yend=yend),
               arrow = arrow(length = unit(0.2, "cm"))) +
  geom_segment(data = df.seg3, aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_segment(data = df.seg4, aes(x=x, y=y, xend=xend, yend=yend),
               arrow = arrow(length = unit(0.2, "cm"))) +
  geom_line(aes(colour = Precision), size = 1) + 
  scale_color_viridis_d(end = 0.9) +
  scale_x_continuous(breaks=nseq, 
            labels = c("10",  "",  "30", "", "50",  "", "70", "", "90", "", "150", "200", "300")) + 
  scale_y_continuous(breaks=seq(0, 1, 0.1)) +
  coord_cartesian(ylim=c(0, 1)) +
  theme(plot.title = element_text(size=20),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 14, colour="black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = "right",
        legend.text=element_text(size = 16),
        legend.title=element_text(size = 18),
        panel.background = element_rect(fill="grey90")) +
  labs(x = "Sample size", y = "Proportion of estimates") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
    title = "Precision \n(within +/-)")) + # change legend title
  # ggtitle("Measurement precision (\u03c1=0.4)") 
  ggtitle("Measurement precision (rho=0.4)") 
p

# save figure
# ggsave(filename='./figures/figure_precision_rho04.pdf',width=9,height=5) 
```

For 70% of estimates to be within +/- 0.1 of the true correlation value (between 0.3 and 0.5), we need at least `r round(approx(y=nseq,x=res.pre[4,],xout=0.70)$y)` observations.

For 90% of estimates to be within +/- 0.2 of the true correlation value (between 0.2 and 0.6), we need at least `r round(approx(y=nseq,x=res.pre[8,],xout=0.90)$y)` observations.

# Probability to replicate an effect (rho=0.4)
For a given precision, what is the probability to observe similar effects in two consecutive experiments? In other words, what is the probability that two measurements differ by at most a certain amount?

## Parameters
```{r}
nseq <- c(seq(10, 100, 10), 150, 200, 300) # sample sizes
Nn <- length(nseq)
preseq <- seq(0.025, 0.2, 0.025) # precision bounds
Npre <- length(preseq)
g <- 0
h <- 0
rho <- 0.4
p <- 500 # 124750 correlations - sum(upper.tri(matrix(0, p, p), diag = FALSE))
Nsim <- 20000
```

## Generate data
```{r eval=FALSE}
set.seed(21)
# declare result matrices
res.rep <- matrix(data = 0, nrow = Npre, ncol = Nn)

for(iter.n in 1:Nn){
  beep(2)
  print(paste0("Sample size = ", nseq[iter.n]))
  allcorr1 <- replicate(Nsim, cor(MASS::mvrnorm(n = nseq[iter.n], mu = c(0,0), Sigma = matrix(c(1, rho, rho, 1), nrow = 2, byrow = TRUE)))[1,2])
  
  allcorr2 <- replicate(Nsim, cor(MASS::mvrnorm(n = nseq[iter.n], mu = c(0,0), Sigma = matrix(c(1, rho, rho, 1), nrow = 2, byrow = TRUE)))[1,2])
  
  # Probability of getting estimates at most x units of each other
  for(iter.p in 1:Npre){
    res.rep[iter.p, iter.n] <- mean( abs(allcorr1-allcorr2) <= (preseq[iter.p]*2) )
  }
  
}

save(res.rep,
     file = "./data/replication_rho04.RData")
beep(8)
```

## Illustrate results
```{r}
load("./data/replication_rho04.RData")
df <- tibble(`Proportion` = as.vector(res.rep),
             `Precision` = rep(preseq*2, Nn),
             `Size` = rep(nseq, each = Npre))

df$Precision <- as.character(df$Precision)
df$Precision <- factor(df$Precision, levels=unique(df$Precision))

# data frame to plot segments
tmp.pos <- approx(y=nseq,x=res.rep[4,],xout=0.8)$y
df.seg1 <- tibble(x=0, xend=tmp.pos,
                  y=0.8, yend=0.8)
df.seg2 <- tibble(x=tmp.pos, xend=tmp.pos,
                  y=0.8, yend=0)

# make plot
p <- ggplot(df, aes(x=Size, y=Proportion)) + theme_classic() +
  geom_segment(data = df.seg1, aes(x=x, y=y, xend=xend, yend=yend)) +
  geom_segment(data = df.seg2, aes(x=x, y=y, xend=xend, yend=yend),
               arrow = arrow(length = unit(0.2, "cm"))) +
  geom_line(aes(colour = Precision), size = 1) + 
  scale_color_viridis_d(end = 0.9) +
  scale_x_continuous(breaks=nseq, 
            labels = c("10",  "",  "30", "", "50",  "", "70", "", "90", "", "150", "200", "300")) + 
  scale_y_continuous(breaks=seq(0, 1, 0.1)) +
  coord_cartesian(ylim=c(0, 1)) +
  theme(plot.title = element_text(size=20),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 14, colour="black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = "right",
        legend.text=element_text(size = 16),
        legend.title=element_text(size = 18),
        panel.background = element_rect(fill="grey90")) +
  labs(x = "Sample size", y = "Proportion of replications") +
  guides(colour = guide_legend(override.aes = list(size=3), # make thicker legend lines
    title = "Difference \n(at most)")) + # change legend title
  # ggtitle("Replication precision (\u03c1=0.4)") 
ggtitle("Replication precision (rho=0.4)") 
p

# save figure
# ggsave(filename='./figures/figure_replication_rho04.pdf',width=9,height=5) 
```

For 80% of replications to be at most 0.2 apart, we need at least `r round(approx(y=nseq,x=res.rep[4,],xout=0.8)$y)` observations.

# Summary figures

## Sampling distributions
```{r, eval=FALSE}
# combine panels into one figure
cowplot::plot_grid(p.sd,  p.sd04, p.csd, p.csd04,
                          labels = c("A", "C", "B", "D"),
                          ncol = 2,
                          nrow = 2,
                          rel_widths = c(1, 1, 1, 1), 
                          label_size = 20, 
                          hjust = -0.5, 
                          scale=.95,
                          align = "h")
# save figure
ggsave(filename=('./figures/figure_samp_dist.pdf'),
         width=15, height=12, device = cairo_pdf)
```

## Precision & replication
Not included in article.

```{r eval=FALSE}
# combine panels into one figure
cowplot::plot_grid(p.precision,  p.replication,
                          labels = c("A", "B"),
                          ncol = 1,
                          nrow = 2,
                          rel_widths = c(1, 1), 
                          label_size = 20, 
                          hjust = -0.5, 
                          scale=.95,
                          align = "h")
# save figure
ggsave(filename=('./figures/figure_prec_rep.pdf'),
       width=7, height=10, device = cairo_pdf)
```

---
title: "Sampling distributions for percent correct data"
author: "Guillaume A. Rousselet"
date: "`r Sys.Date()`"
output:
  pdf_document:
    fig_caption: no
    number_sections: no
    toc: yes
    toc_depth: 2
---

# Dependencies
```{r message=FALSE, warning=FALSE}
library(ggplot2)
source("./functions/theme_gar.txt") # define ggplot theme
library(tibble)
library(cowplot)
source("./functions/akerd.txt")
# install.packages("devtools")
# devtools::install_github("GRousselet/rogme")
library(rogme)
library(beepr)
library(Rfast) # to fit beta distribution using MLE
```

```{r}
sessionInfo()
```

# Relationship between PC and SE

The population mean percent correct and standard deviation are dependent: there is stronger variability at 50% correct and the variability decreases as the mean tends toward zero or 1.

## Generate data from 1 participant, 10000 simulations/experiments.
```{r}
nsim <- 10000
nt <- 100 # number of trials
pc.seq <- seq(.1, .9, .1)
sim.res <- matrix(NA, nrow = nsim, ncol = length(pc.seq))
for(PC in 1:length(pc.seq)){
  sim.res[,PC] <- rbinom(nsim, nt, pc.seq[PC]) / nt    
}
```

### Illustrate results
```{r}
df <- tibble(pc = as.vector(sim.res),
             m = factor(rep(pc.seq, each = nsim)))

ggplot(df, aes(x = pc, group = m, colour = m)) + theme_gar +
  geom_line(stat = "density", size = 1.5) +
  labs(x = "Percent correct", y = "Density") +
  scale_colour_viridis_d(option = "cividis")
```

## Theoretical distributions

Here we illustrate the theoretical relative probabilities of observing different proportions of correct responses for different true values. For instance, given that a participant is on average 10% correct, what is the distribution of the number of correct trials we can expect? For any given experiment, the number of correct trials ranges from roughly 0 to 20. If the population average is 50%, the values across experiments range from 45 to 65. 
```{r}
# df <- tibble(x = seq(0, 100, 0.01))
x <- seq(0, 100, 1)
nt <- 100 # sample size
pc.seq <- seq(.1, .9, .1)
res <- matrix(NA, nrow = length(x), ncol = length(pc.seq))
for(PC in 1:length(pc.seq)){
  res[,PC] <- dbinom(x, size = nt, prob = pc.seq[PC])
}

df <- tibble(pc = rep(x,length(pc.seq)),
             dens = as.vector(res),
             cond = factor(rep(pc.seq*100, each = length(x)))
             )

# scales::show_col(scales::viridis_pal(option="inferno")(9))
# cc <- scales::viridis_pal(option="inferno")(9)

p <- ggplot(df, aes(x = pc, y = dens, colour = cond)) + theme_gar +
  geom_line(size = 1.5) +
  guides(colour = guide_legend(override.aes = list(size = 3),
                               title = "Population\nproportion correct")) +
  scale_colour_viridis_d(option = "cividis") + 
  scale_x_continuous(breaks = seq(0, 100, 10)) +
  labs(x = "Number of correct trials",
       y = "Density") +
  ggtitle("Binomial PDFs for n = 100 trials")

# for(PC in 1:length(pc.seq)){
#   p <- p + stat_function(fun = dbinom, 
#                          args = list(size = nt, prob = pc.seq[PC]),
#                          size = 1.5,
#                          colour = cc[PC]) 
# }
pA <- p
p
```

Distributions are bounded and the variance varies with the mean, so this type of data should not be modelled using metric scales as in standard t-test and ANOVA.

# Example of percent correct data from lexical decision dataset

Percent correct data are not normaly distributed. In this example, participants tend to perform very well, with many averages above 90%. Some participants are not as good, leading to negative skewness. We illustrate the data and then fit a beta distribution. Then we move to a made-up example with an average of 70% correct.

Data from the [French Lexicon Project](https://sites.google.com/site/frenchlexicon/results).
Click on "French Lexicon Project trial-level results with R scripts.zip".
The `.RData` dataset was created by applying the script `getflprtdata.Rmd` available on [GitHub](https://github.com/GRousselet/rogme/tree/master/data-raw).

```{r}
# get data - tibble = `flp`
flp <- rogme::flp
# columns =
#1 = participant
#2 = rt
#3 = acc = accuracy 0/1
#4 = condition = word/non-word

# get accuracy data
flp.acc <- tapply(flp$acc, list(flp$participant, flp$condition), mean)
summary(flp.acc)
```

## Illustrate data
```{r}
# make KDE
flp.w <- sort(flp.acc[,1])
flp.nw <- sort(flp.acc[,2])
a.flp.w <- akerd(flp.w, pyhat = TRUE, plotit = FALSE)
a.flp.nw <- akerd(flp.nw, pyhat = TRUE, plotit = FALSE)

# create data frame
df <- tibble(`x`=c(flp.w,flp.nw),
             `y`=c(a.flp.w,a.flp.nw),
             `Condition`=c(rep.int("Word",length(flp.w)),
                           rep.int("Non-word",length(flp.nw))))
# make plot
df$Condition <- as.character(df$Condition)
df$Condition <- factor(df$Condition, levels=unique(df$Condition))

# make plot
p <- ggplot(df, aes(x,y, group=Condition)) + theme_classic() + 
  geom_line(aes(colour=Condition), size = 1.5) + # linetype=Condition, 
  # scale_size_manual(values=c(1,0.5)) +
  # scale_linetype_manual(values=c("solid","solid")) +
  scale_color_manual(values=c("grey30", "#E69F00")) + #, "#56B4E9","black")) + grey #999999
  scale_x_continuous(limits=c(0,1), breaks=seq(0,1,0.1), minor_breaks = waiver()) +
  theme(plot.title = element_text(size=22),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 16, colour = "black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = c(0.25,0.8),
        legend.title = element_text(size=16),
        legend.text = element_text(size = 14),
        strip.text.y = element_text(size = 18, face = "bold", angle = 0)) +
        # legend.position = c(0.25,0.9)) +
  labs(x = "Proportion correct", y = "Density") +
  ggtitle("Lexical decision")
p
# save figure
# ggsave(filename='./figures/figure_flp_all_p_acc.pdf',width=10,height=7) #path=pathname
```

## Fit beta distributions

### Test function

Estimated parameters are close to the expected ones.
```{r}
set.seed(666)
alpha <- 20 # 10 # 5
beta <- 8.56 # 4.28 # 2.14
nt <- 300
samp <- rbeta(nt, alpha, beta)
hist(samp, 50)
beta.mle(samp)
```

### Apply to FLP data

Word condition
```{r}
fit.w <- beta.mle(flp.w)
fit.w
```

Non-Word condition
```{r}
beta.mle(flp.nw)
```

Real and fitted data
```{r}
# make KDE
flp.w <- sort(flp.acc[,1])
flp.nw <- sort(flp.acc[,2])
a.flp.w <- akerd(flp.w, pyhat = TRUE, plotit = FALSE)
# a.flp.nw <- akerd(flp.nw, pyhat = TRUE, plotit = FALSE)
x.seq <- seq(0,1,0.001)
a.flp.w.f <- dbeta(x.seq, fit.w$param[1], fit.w$param[2])

# create data frame
df <- tibble(`x`=c(flp.w,x.seq),
             `y`=c(a.flp.w,a.flp.w.f),
             `Condition`=c(rep.int("Original",length(flp.w)),
                           rep.int("Beta fit",length(x.seq))))
# make plot
df$Condition <- as.character(df$Condition)
df$Condition <- factor(df$Condition, levels=unique(df$Condition))

# make plot
p <- ggplot(df, aes(x,y, group=Condition)) + theme_classic() + 
  geom_line(aes(colour=Condition, size=Condition)) + # linetype=Condition, 
  scale_size_manual(values=c(1.5,0.75)) +
  # scale_linetype_manual(values=c("solid","solid")) +
  scale_color_manual(values=c("grey30", "#E69F00")) + #, "#56B4E9","black")) + grey #999999
  scale_x_continuous(limits=c(0,1), breaks=seq(0,1,0.1), minor_breaks = waiver()) +
  theme(plot.title = element_text(size=22),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 16, colour = "black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = c(0.25,0.8),
        legend.title = element_text(size=16),
        legend.text = element_text(size = 14),
        strip.text.y = element_text(size = 18, face = "bold", angle = 0)) +
        # legend.position = c(0.25,0.9)) +
  labs(x = "Proportion correct", y = "Density") #+
  # ggtitle("Lexical decision")
p
```

Real and fitted data: normality assumption
```{r}
x.seq <- seq(0,1.5,0.001)
fit.w.n <- normal.mle(flp.w)
a.flp.w.f <- dnorm(x.seq, fit.w.n$param[1], sqrt(fit.w.n$param[2]))

# create data frame
df <- tibble(`x`=c(flp.w,x.seq),
             `y`=c(a.flp.w,a.flp.w.f),
             `Condition`=c(rep.int("Original",length(flp.w)),
                           rep.int("Normal fit",length(x.seq))))
# make plot
df$Condition <- as.character(df$Condition)
df$Condition <- factor(df$Condition, levels=unique(df$Condition))

# make plot
p <- ggplot(df, aes(x,y, group=Condition)) + theme_classic() + 
  geom_line(aes(colour=Condition, size=Condition)) + # linetype=Condition, 
  scale_size_manual(values=c(1.5,0.75)) +
  # scale_linetype_manual(values=c("solid","solid")) +
  scale_color_manual(values=c("grey30", "#E69F00")) + #, "#56B4E9","black")) + grey #999999
  scale_x_continuous(limits=c(0,1.1), breaks=seq(0,1.2,0.1), minor_breaks = waiver()) +
  theme(plot.title = element_text(size=22),
        axis.title.x = element_text(size = 18),
        axis.text = element_text(size = 16, colour = "black"),
        axis.title.y = element_text(size = 18),
        legend.key.width = unit(1.5,"cm"),
        legend.position = c(0.25,0.8),
        legend.title = element_text(size=16),
        legend.text = element_text(size = 14),
        strip.text.y = element_text(size = 18, face = "bold", angle = 0)) +
        # legend.position = c(0.25,0.9)) +
  labs(x = "Proportion correct", y = "Density") #+
  # ggtitle("Lexical decision")
p
```

# Mean percentage correct = 0.7

Consider example at level 1: percent correct values across participants follow a beta distribution. Let say participants are on average 70% correct. 

## Define beta distribution for target PC
```{r}
# param <- estBetaParams(0.7, .1)
x <- seq(0, 1, 0.1)
alpha <- 20 # 10 # 5
beta <- 8.56 # 4.28 # 2.14
beta.m <- alpha/(alpha+beta)
p <- ggplot(as.tibble(x), aes(x = x)) + theme_gar +
  stat_function(fun = dbeta, 
                args = list(shape1 = alpha, shape2 = beta),
                size = 1.5) +
  geom_vline(xintercept = beta.m) +
  scale_x_continuous(breaks = seq(0, 1, 0.1)) +
  labs(x = "Proportion correct",
       y = "Density") +
  ggtitle(paste0("Beta distribution: alpha=",alpha,", beta=",beta,", mean=",round(beta.m,digits=3)))
pB <- p
p
```

## Examples of random samples
```{r}
set.seed(22222)

nsamp <- 10
np <- 10 # number of participants
nt <- 100 # number of trials
pc <- 0.7 # percent correct
sim.res <- matrix(NA, nrow = nsamp, ncol = np) 

for(S in 1:nsamp){ # samples
  for(P in 1:np){ # participants
    sim.res[S,P] <- mean(rbinom(nt, 1, rbeta(1, alpha, beta)))
  }
}

df <- tibble(PC = as.vector(sim.res),
             Samples = rep(1:nsamp, np))

df2 <- tibble(PC = apply(sim.res, 1, mean),
              Samples = 1:nsamp)

p <- ggplot(df, aes(x = PC, y = Samples)) + theme_gar +
  geom_jitter(height = .15, alpha = 1,
              shape = 21, fill = "grey", colour = "black") +
  geom_segment(data = df2, 
               aes(x=PC, xend=PC, y=Samples-0.3, yend=Samples+0.3),
               size = 0.75) +
  geom_vline(xintercept = beta.m) +
  theme(panel.grid.minor.y = element_blank()) +
  scale_x_continuous(breaks = seq(0.4, 1, .1)) +
  scale_y_continuous(breaks = seq(1, 10, 1)) +
  labs(x = "Proportion correct") +
  ggtitle(paste0("Random samples: ",np," participants,",nt," trials"))
pC <- p
p
```

## Generate group data: simple example 1

10 participants, 100 trials per participant
```{r}
set.seed(22222)

nsim <- 20000
np <- 10 # number of participants
nt <- 100 # number of trials
pc <- 0.7 # percent correct
sim.res <- matrix(NA, nrow = nsim, ncol = np) 

for(S in 1:nsim){
  for(P in 1:np){
    sim.res[S,P] <- mean(rbinom(nt, 1, rbeta(1, alpha, beta)))
  }
}
# res <- matrix(rbinom(np * nsim, nt, pc), nrow = nsim)
samp_dist <- apply(sim.res, 1, mean)
m <- round(mean(samp_dist), digits = 2)
sdev <- round(sd(samp_dist), digits = 2)
```

### Illustrate results
```{r}
ggplot(tibble(x = samp_dist), aes(x = x)) + theme_gar +
  geom_line(stat = "density", size = 1.5) +
  labs(x = "Mean percent correct", y = "Density") +
  ggtitle(paste0("Group sampling distribution: m=",m," sd=",sdev))
```

### Probability of observing PC more than 5% points from the mean?
What is the probability of observing a group result more than 5% points from the population mean of 70%?
```{r}
round(mean(abs(samp_dist-0.7) >= 0.05)*100, digits = 1)
```

## Generate group data: simple example 2

10 participants, 50 trials per participant
```{r}
set.seed(22222)

nsim <- 20000
np <- 10 # number of participants
nt <- 50 # number of trials
pc <- 0.7 # percent correct
sim.res <- matrix(NA, nrow = nsim, ncol = np) 

for(S in 1:nsim){
  for(P in 1:np){
    sim.res[S,P] <- mean(rbinom(nt, 1, rbeta(1, alpha, beta)))
  }
}
# res <- matrix(rbinom(np * nsim, nt, pc), nrow = nsim)
samp_dist <- apply(sim.res, 1, mean)
m <- round(mean(samp_dist), digits = 2)
sdev <- round(sd(samp_dist), digits = 2)
```

### Illustrate results
```{r}
ggplot(tibble(x = samp_dist), aes(x = x)) + theme_gar +
  geom_line(stat = "density", size = 1.5) +
  labs(x = "Mean percent correct", y = "Density") +
  ggtitle(paste0("Group sampling distribution: m=",m," sd=",sdev))
```

### Probability of observing PC for 5% points from the mean?
```{r}
round(mean(abs(samp_dist-0.7) >= 0.05)*100, digits = 1)
```

## Generate group data: simple example 3

50 participants, 10 trials per participant
```{r}
set.seed(22222)

nsim <- 20000
np <- 50 # number of participants
nt <- 10 # number of trials
pc <- 0.7 # percent correct
sim.res <- matrix(NA, nrow = nsim, ncol = np) 

for(S in 1:nsim){
  for(P in 1:np){
    sim.res[S,P] <- mean(rbinom(nt, 1, rbeta(1, alpha, beta)))
  }
}
# res <- matrix(rbinom(np * nsim, nt, pc), nrow = nsim)
samp_dist <- apply(sim.res, 1, mean)
m <- round(mean(samp_dist), digits = 2)
sdev <- round(sd(samp_dist), digits = 2)
```

### Illustrate results
```{r}
ggplot(tibble(x = samp_dist), aes(x = x)) + theme_gar +
  geom_line(stat = "density", size = 1.5) +
  labs(x = "Mean percent correct", y = "Density") +
  ggtitle(paste0("Group sampling distribution: m=",m," sd=",sdev))
```

### Probability of observing PC for 5% points from the mean?

Happened once in 20,000 experiments
```{r}
# sprintf("%f",mean(abs(samp_dist-0.7) >= 0.05),5)
round(mean(abs(samp_dist-0.7) >= 0.05)*100, digits = 1)
```

## Generate group data: full example
```{r}
set.seed(22222)

nsim <- 20000
np.seq <- c(10, 20, 50) # number of participants
maxNP <- max(np.seq)
nt.seq <- c(10, 20, 50, 100, 200) # number of trials
pc <- 0.7 # percent correct
sim.res <- array(NA, dim = c(nsim, maxNP, length(nt.seq))) 

for(S in 1:nsim){
  for(P in 1:maxNP){
    for(T in 1:length(nt.seq)){
    sim.res[S,P,T] <- mean(rbinom(nt.seq[T], 1, rbeta(1, alpha, beta)))
    }
  }
}
samp_dist10 <- apply(sim.res[,1:10,], c(1,3), mean)
samp_dist20 <- apply(sim.res[,1:20,], c(1,3), mean)
samp_dist50 <- apply(sim.res[,1:50,], c(1,3), mean)
```

### Illustrate results
```{r}

df <- tibble(x = c(as.vector(samp_dist10),
                   as.vector(samp_dist20),
                   as.vector(samp_dist50)),
             np = factor(rep(c("10", "20", "50"), each = nsim * length(nt.seq))),
             nt = factor(rep(rep(nt.seq, each = nsim),3)))

p <- ggplot(df, aes(x = x, colour = nt)) + theme_gar +
  geom_vline(xintercept = beta.m) +
  geom_line(stat = "density", size = 0.75) +
  theme(legend.position = "bottom") +
  guides(colour = guide_legend(override.aes = list(size = 3),
                               title = "Number of trials")) +
  scale_colour_viridis_d(option = "plasma", 
                         begin = 0, end = 0.7) + 
  facet_grid(cols = vars(np)) +
  labs(x = "Group mean proportion correct", y = "Density")
pD <- p
p
```

# Summary figure
```{r, eval = FALSE}

cowplot::plot_grid(pA, pB, pC, pD,
                    labels = c("A", "B", "C", "D"),
                    ncol = 1,
                    nrow = 4,
                    rel_heights = c(1, 1, 1, 1), 
                    label_size = 20,
                    # align = 'v',
                    # axis = 'l',
                    # hjust = -0.5, 
                    scale = 1)

# save figure
ggsave(filename=('./figures/figure_pc.pdf'),width=10,height=20)
```

